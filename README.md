# rag_chat_memory
This project is a local Conversational RAG (Retrieval-Augmented Generation) system based on Flask + LangChain + Ollama. It integrates multiple data sources (local vector DB, Wikipedia, and web scraping), enables interaction with local LLM models, and includes a full-featured Web UI.
